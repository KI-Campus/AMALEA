{"cells":[{"cell_type":"code","execution_count":null,"source":["# [Nur Colab] Diese Zellen müssen nur auf *Google Colab* ausgeführt werden und installieren Packete und Daten\n","!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n","!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Maschinelles Lernen und seine Anwendungen\n","\n","### Einführung\n","\n","Wir beginnen diesen Abschnitt mit der Definition einiger Schlüsselbegriffe, die wir in dieser Übung verwenden werden.\n","\n","__Datensatz (engl. Dataset):__ Eine Sammlung von Daten wird als Datensatz bezeichnet. Im Allgemeinen ist sie wie eine Tabelle aufgebaut. Jede Zeile repräsentiert ein Element, das mehrere Features haben kann. Jede Spalte repräsentiert ein Feature.\n","\n","\n","__Deskriptive Statistik:__ Sie ist der Vorläufer der _Prädiktiven Statistik_ und basiert auf dem Gewinnen und Zusammenfassen von Informationen aus vergangenen Ereignissen. Zu den grundlegenden deskriptiven Analysetechniken gehören Anzahl, Summe, Durchschnittswert, Prozentsatz, Minimal- und Maximalwert sowie einfache Arithmetik (+, -, × und ÷).  \n","\n","\n","__Prädiktive Statistik:__ Das Ergebnis einer Weiterentwicklung des Konzepts der _deskriptive Analytik_. Ihr Ziel ist es, basierend auf der Analyse historischer Daten, Vorhersagen über die Zukunft oder über unbekannte Ereignisse zu treffen. Um dies zu erreichen, werden bestimmte Modelle oder Algorithmen verwendet.\n","\n","![Imagen predictive analytics](images/predictive_analytics_in_a_pic.png)\n","\n","__Maschinelles Lernen:__ Ist ein Ansatz zum Lösen von Problemen der _Prädiktiven Statistik_. Anstatt explizit definierte Regeln zur Verarbeitung von Daten anzuwenden, versucht maschinelles Lernen, die zugrunde liegenden allgemeinen Konzepte der Beziehungen im Datensatz herauszufinden. Diese Methoden sind in der Lage, die traditionelle regelbasierte Programmierung bei vielen Aufgaben weit zu übertreffen, haben aber auch ihre eigenen Komplikationen und Nachteile, die sorgfältig abgewogen werden müssen.\n","\n","\n","In dieser Übung werden Sie lernen, Ansätze des maschinellen Lernens anzuwenden, um fundierte (aus Trainingsdaten gelernte) Vermutungen für die Vorhersage aufzustellen.\n","\n","Beim maschinellen Lernen lernt ein _Prädiktionsmodell_ seine Parameter aus Trainingsdaten. Damit ist das System in der Lage, Vorhersagen aus Eingabedaten zu erstellen. Ein besonderes Merkmal vieler Algorithmen des maschinellen Lernens ist die Fähigkeit, Informationen aus den Trainingsdaten interpolieren und extrapolieren zu können. Es gibt jedoch einige Einschränkungen bei der Generalisierung. Zudem wird das Modell wahrscheinlich am besten mit Daten funktionieren, die den Trainingsdaten ähnlich sind. Daher werden wir unsere Daten meistens in Trainings-, Test- und Validierungsdaten aufteilen. Diese drei Konzepte sind für fast alle Aufgaben des maschinellen Lernens wichtig und werden im Folgenden definiert:\n","\n","\n","- Trainingsdaten: Die Daten und Beispiele, die für die Optimierung der Parameter des Modells verwendet werden. \n","- Testdaten: Normalerweise wollen wir wissen, wie gut der maschinelle Lernalgorithmus mit Daten umgeht, die er zuvor noch nicht gesehen hat. Dadurch können wir abschätzen, wie gut der Algorithmus in der realen Welt funktionieren würde. Diese Leistungsmaße evaluieren wir daher mit einem Testdatensatz, der von den Daten getrennt ist, die für das Training des maschinellen Lernsystems verwendet wurden. (Legen Sie diese Daten beseite und evaluieren Sie nur einmal am Ende Ihrer Optimierung! Sie sollten nicht mit Testdaten trainieren...)\n","- Validierungsdaten: Der Validierungssatz wird verwendet, um den Generalisierungsfehler während oder nach dem Training zu schätzen, sodass die Hyperparameter (z. B. Lernrate, k, Baumtiefe, Batch-Größe, ...) unabhängig von Test- und Trainingsdaten aktualisiert werden können. Daher ist es wichtig, die Validierungsdaten von Test- und Trainingsdaten zu trennen. Typischerweise verwendet man etwa 80 % der Trainingsdaten für das Training und 20 % für die Validierung.\n","\n","<!--- www.digitalistmag.com/digital-economy/2018/03/15/differences-between-machine-learning-predictive-analytics-05977121 -->\n","\n","Das Ziel der _Prädiktiven Modellierung_ ist es, Modelle zu erstellen, die gute Vorhersage treffen. Dies wird erreicht, indem das Modell mithilfe der Trainingsdaten trainiert wird. Die Performanz des Modells wird anschließend mit den Testdaten bestimmt. Für das Optimieren der Hyperparameter werden die Validierungsdaten verwendet. __In dieser Übung werden jedoch keine Hyperparameter optimiert.__ Dementsprechend wird kein Validierungssatz benötigt und alle Daten werden für Training und Test verwendet. Sie werden verschiedene Methoden kennenlernen, um Ihre Daten in Trainings- und Testsätze zu unterteilen.\n","Zudem werden Sie lernen, wie sie diese Daten verwenden können, um ein maschinelles Lernmodell zu trainieren.\n","\n","Es gibt mehrere Algorithmen/Netzwerke, die als Vorhersagemodelle verwendet werden können, prominente Beispiele sind:\n","- K-Nearest Neighbor Algorithmen\n","- Neuronale Netze (Multi Layer Perceptrons MLPs)\n","- Convolutional Neural Networks (CNNs)\n","- Recurrent Neural Networks (RNNs)\n","- Und viele weitere\n","\n","\n","![xkcd.png](images/xkcd.png)\n","\n","### Anwendungen\n","\n","\n","### Regressionsprobleme\n","Im Falle von Regressionsproblemen muss ein maschinelles Lernmodell eine _Größe_ (kontinuierlicher Wert) auf Basis von neuen Daten vorhersagen. In der Praxis funktioniert das, indem eine Funktion auf einen bekannten Satz von Datenpunkten angepasst wird. Die Vorhersage des Modells ist nichts anderes als die Ausgabe der Funktion mit der neuen Eingabe.\n","\n","Häufig verwendete Regressionsmethoden sind die _lineare Regression_ und die _logistische Regression_.\n","Lineare Funktionen sind einfach anzupassen und zu verstehen. Allerdings kann die Genauigkeit gering ausfallen, wenn die den Daten zugrunde liegende Beziehung nichtlinear ist. Die logistische Regression passt eine logistische Sigmoidkurve an die gegebenen Daten an. Diese wird normalerweise verwendet, um eine Wahrscheinlichkeitsfunktion zu approximieren, die später als Grundlage für eine Klassifizierungsentscheidung verwendet werden kann.\n","\n","\n","![linear_logistic_regression](images/linear_logistic_regression.jpeg)\n","\n","\n","### Klassifizierungsprobleme\n","Bei Klassifizierungsproblemen versucht das Modell, eine diskrete Klasse oder Kategorie von neuen Daten vorherzusagen. \n","Um ein Klassifizierungsproblem zu lösen, kann man grundsätzlich auch zunächst ein Regressionsmodell erstellen. Für die Klassifizierung werden jedoch andere Metriken und Modellfunktionen (z. B. logistisch) gewählt. Zusätzlich werden Schwellenwerte für die Klassifikation auf die Modellvorhersage angewendet, um eine diskrete Ausgabe zu erzeugen.\n","\n","![regression_classification_weather_example](images/regression_classification_weather_example.jpeg)\n","<p style=\"text-align: center;\">\n","    Abb. 1 - Regression und Klassifizierung auf Basis der Wettervorhersage\n","</p>\n","\n","\n","\n","Sowohl Regressions- als auch Klassifikationsprobleme können mit Methoden des _überwachten Lernens_ gelöst werden.  Bei diesem Ansatz müssen sowohl die Eingabe als auch die entsprechende Lösung (Label) im Voraus bekannt sein. Eingaben und Labels werden dann dem Algorithmus übergeben. Dieser versucht dann, eine allgemeine, konzeptionelle Beziehung zwischen Eingaben und Lösungen zu lernen, bis er schließlich in der Lage ist, eine sinnvolle Ausgabe für neue Eingaben zu liefern.\n","\n","### Clustering-Probleme\n","Unüberwachte Lernmethoden wie Clustering benötigen keine Lösungsmenge, um zu funktionieren. Wir werden uns hier nicht auf ihre Leistungsmetriken konzentrieren, da dies tiefergehendes Wissen erfordert. Sie werden mehr über Clustering in Woche 3 erfahren.\n"],"metadata":{}},{"cell_type":"markdown","source":["## Aufteilen von Datensätzen in Trainings- und Testsätze\n","\n","Wenn Sie mit einem Modell arbeiten und es trainieren wollen, verfügen Sie bereits über einen Datensatz. Um das Modell nach dem Training zu testen, benötigen Sie neue Daten, die noch nicht im Trainingssatz aufgetreten sind. Vor allem in frühen Entwicklungsphasen kann es allerdings sein, dass Ihnen dazu keine große Menge an Daten zur Verfügung steht.\n","\n","In solchen Situationen ist die naheliegendste Lösung, den vorhandenen Datensatz in zwei Gruppen zu unterteilen, eine zum Trainieren und eine zum Testen. Diese Unterteilung führen Sie noch vor Beginn des Trainings durch. Ein Teil wird zum Trainieren des Modells verwendet. Sobald die Maschine trainiert ist, werden wir die Vorhersagen mit den Testdaten vergleichen, um die Leistung des Modells abzuschätzen.\n","\n","Die Größe der Aufteilung kann von der Größe und den Eigenschaften des Datensatzes abhängen. Allerdings ist es üblich, 67 % der Daten zum Trainieren und die restlichen 33 % zum Testen zu verwenden. Ein Split-Verhältnis von 80/20 ist ebenfalls sehr üblich. \n","\n","Diese Auswertungstechnik des Algorithmus ist sehr schnell. Sie ist ideal für große Datensätze (Millionen von Einträgen), bei denen es starke Hinweise darauf gibt, dass beide Aufteilungen (engl. splits) der Daten das zugrunde liegende Problem repräsentieren. Wegen der Geschwindigkeit ist es sinnvoll, diesen Ansatz zu verwenden, wenn der zu untersuchende Algorithmus langsam beim Training oder bei der Inferenz ist. \n","Ein Nachteil dieser Technik ist, dass sie eine hohe Varianz haben kann. Das bedeutet, dass Unterschiede im Trainings- und Testdatensatz zu bedeutenden Unterschieden in der Schätzung der Genauigkeit führen können.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.1.1:</b> Führen Sie den folgenden Codeblock aus und spielen Sie mit den Kontrollkästchen. Nutzen Sie Ihre gewonnenen Erkenntnisse, um die folgenden Aufgaben zu lösen.\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Nun sind Sie dran:</b> Führen Sie den Code im nächsten Codeblock aus. Der Code führt eine lineare Regression für einen beispielhaften Diabetes-Datensatz durch. Weitere Informationen zu diesem Datensatz finden Sie unter: \n","<a href=\"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\">https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html</a>    \n"," oder im ganzen Paper <a href=\"http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf\">http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf</a> (seien Sie gewarnt, es sind etwa 44 Seiten. Es ist nicht empfehlenswert, alles zu lesen). Außerdem erzeugt der Code ein interaktives Diagramm, um Ihnen bei der Lösung der ersten Aufgabe zu helfen.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["# Code source: Jaques Grobler\n","# License: BSD 3 clause\n","\n","# https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn import datasets, linear_model\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","from ipywidgets import interact, interactive, fixed, interact_manual\n","\n","# Load the diabetes dataset\n","diabetes = datasets.load_diabetes()\n","\n","# Use only one feature\n","diabetes_X = diabetes.data[:, np.newaxis, 2]\n","\n","# Split the data into training/testing sets\n","diabetes_X_train = diabetes_X[:-20]\n","diabetes_X_test = diabetes_X[-20:]\n","\n","# Split the targets into training/testing sets\n","diabetes_y_train = diabetes.target[:-20]\n","diabetes_y_test = diabetes.target[-20:]\n","\n","# Create linear regression object\n","regr = linear_model.LinearRegression()\n","\n","# Train the model using the training sets\n","regr.fit(diabetes_X_train, diabetes_y_train)\n","\n","# Make predictions using the testing set\n","diabetes_y_pred = regr.predict(diabetes_X_test)\n","\n","# The coefficients\n","print('Coefficients: \\n', regr.coef_)\n","\n","def f(p1: bool, p2: bool, p3: bool, p4: bool):\n","    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n","\n","    # Plot outputs\n","    if p1 == True:\n","        plt.scatter(diabetes_X_train, diabetes_y_train,  color='black')\n","    #plt.scatter(diabetes_X_train, diabetes_y_pred, color='blue')\n","    \n","    if p2 == True:\n","        plt.scatter(diabetes_X_test, diabetes_y_test,  color='green')\n","\n","    if p3 == True:\n","        plt.scatter(diabetes_X_test, diabetes_y_pred, color='blue')\n","\n","    if p4 == True:\n","        plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=1)\n","    \n","    plt.xlim(-0.10997004779892904, 0.19024997788107048)\n","    plt.ylim(8.940894039735102, 362.05910596026484)\n","    \n","    # this hides the numbers on the axis\n","    #plt.xticks(())\n","    #plt.yticks(())\n","\n","    plt.show()\n","    \n","interactive_plot = interactive(f, p1=True, p2=True, p3=True, p4=True)\n","output = interactive_plot.children[-1]\n","output.layout.height = '400px'\n","interactive_plot\n"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe/Frage 2.1.2:</b> Vervollständigen Sie den folgenden Text, sodass er mit Hilfe der Tabelle unten und der interaktiven Grafik widerspruchsfrei ist, und vervollständigen Sie dann die Tabelle.\n","\n","    \n","    \n","Der folgende Text beschreibt die Schritte zum Erstellen eines Vorhersagemodells für eine lineare Regression: <br>\n","<br>\n","Indem Sie ??? und ??? betrachten, können Sie einen Blick auf den gesamten Datensatz werfen.  Im obigen Diagramm wird die Aufteilung der Daten durch unterschiedliche Farben dargestellt. Typischerweise wird der Datensatz in Train, Test und Validierung unterteilt, aber für einfache Modelle kann auch eine einfache Test-Train-Aufteilung verwendet werden. In der Regel ist der Trainingssatz (80 %) größer als der Testsatz (20 %).\n","Nach der Aufteilung wird der Trainingssatz an das lineare Regressionsmodell übergeben, das über einen Parameter verfügt, der eine lineare Funktion erzeugt. Sie können diese Funktion einblenden, indem Sie auf ??? klicken.<br>\n","<br>\n","Mithilfe dieser Linie können wir dann die Werte von y für die Werte x des Testsatzes berechnen. Diese Punkte werden durch ??? dargestellt.  \n","<br>\n","Offensichtlich werden alle diese Punkte auf der Linie liegen. In einem nächsten Schritt können verschiedene Metriken berechnet werden, die uns eine Vorstellung davon geben, wie gut dieses Modell mit diesen Daten funktioniert. Mit diesen Metriken würden wir das Modell mit anderen Modellen oder mit anderen Parametern für dieses Modell vergleichen.  \n","<br>\n","Wenn wir mit der Auswahl des Modells und seiner Parameter fertig sind, werden wir das Modell erneut trainieren, dieses Mal mit der kompletten Datenbank. \n","</div>\n","\n","|         -          |        -                     |\n","|--------------------|------------------------------|\n","| Trainingssatz      | ???                     |\n","|--------------------|------------------------------|\n","| Testsatz           | ???                    |\n","|--------------------|------------------------------|\n","| Vorhergesagter Datensatz  | ???                    |\n","|--------------------|------------------------------|\n","| Regressionsfunktion | ???                    |\n","\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.1.3:</b> Jetzt ist es an der Zeit, Ihre eigene Train-Split Funktion zu schreiben. Verwenden Sie die folgenden Anweisungen und die gegebene Codevorlage.\n","<ul>\n","<li> Die Funktion erhält den Originaldatensatz und gibt die beiden Partitionen/Variablen (genannt train und test) zurück.\n","<li> Außerdem erhält die Funktion eine Zahl zwischen 0 und 1, die das prozentuale Größenverhältnis zwischen \"train\" und \"test\" darstellt. Das heißt, wenn z. B. split = 0,7 ist, werden 70 % der Daten für das Training verwendet und die restlichen 30 % sind für das Testen reserviert.\n","<li> Wir wollen, dass die Aufteilung zufällig ist, also müssen Sie wahrscheinlich aus dem Modul <i>\"random.py\"</i> (das Teil der <i>Python-Standardbibliothek</i> ist) die Funktionen <i>seed</i> und <i>randrange</i> importieren. Die <i>seed</i> Funktion sorgt dafür, dass das Ergebnis von <i>randrange</i> bei jeder Codeausführung das gleiche ist.\n","<li>Eine gute Vorgehensweise wäre es, eine Kopie des Originaldatensatzes innerhalb der Funktion zu erstellen. Auf diese Weise wird der Originaldatensatz nicht verändert. Nehmen Sie dann einige Zeilen dieses Datensatzes und fügen Sie diese in eine andere Liste ein. Geben sie beide Listen zurück. Sie können selbst entscheiden können, was train und was test ist.\n","</ul>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["# Example of Splitting a Contrived Dataset into Train and Test\n","from random import seed\n","from random import randrange\n","\n","# Split a dataset into a train and test set\n","def my_train_test_split(dataset: list, split: float):\n","    #STUDENT CODE HERE\n","\n","    #STUDENT CODE until HERE\n","    return train, test"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.1.4:</b> Testen Sie Ihre train_test_split Funktion anhand des folgenden Beispiels: \n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["# test train/test split\n","seed(1)\n","dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]  # Dataset is 1 indexed.\n","train, test = my_train_test_split(dataset,0.7)\n","print(train)\n","print(test)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["Es gibt viele Methoden, um die Aufteilung des Datensatzes (in Trainings- und Test-Sätze) und die Auswertung des Modells, über die wir gerade gesprochen haben, durchzuführen.\n","In diesem Abschnitt lernen wir die zwei Hauptmethoden kennen, diese wären:\n","- Aufteilen, Trainieren und Testen\n","- k-fache Kreuzvalidierung (engl. k-fold cross validation)\n","\n","Neben diesen gibt es noch weitere Methoden, die oben vorgestellten Methoden bilden aber die Grundlagen.  \n","Beiden Verfahren gehören zu den sogenannten __Resampling-Methoden__, also statistischen Methoden, die es ermöglichen, die Leistung des Modells zu __schätzen__, d. h. wie gut es funktionieren wird und wie gut seine Vorhersagen sein werden.\n","Das Ziel von Resampling-Methoden ist es, die Trainingsdaten bestmöglich zu nutzen, um die Leistung eines Modells auf neuen, zuvor ungesehenen Daten möglichst genau zu schätzen.  \n","\n","Sobald wir eine genaue Schätzung der Performanz des Modells erreicht haben, können wir diese verwenden, um zu entscheiden, welchen Satz von Modellparametern wir verwenden oder welches Modell wir auswählen.  \n","Sobald wir ein Modell ausgewählt haben, können wir das endgültige Modell mit dem gesamten Trainingsdatensatz trainieren und damit beginnen, Vorhersagen zu treffen.  \n","Am Ende dieses Abschnitts erfahren Sie, wann Sie welche Resampling-Methode verwenden sollten.\n","\n","Ein gemeinsames Merkmal aller Resampling-Methoden ist die Notwendigkeit, die Zeilen für den Trainings-, Test- und Validierungsdatensatz zufällig auszuwählen.\n","Damit soll sichergestellt werden, dass das Training und die Evaluierung eines Modells objektiv sind.  \n","Wenn mehrere Algorithmen oder mehrere __Konfigurationen__ desselben Algorithmus verglichen werden, sollte der exakt gleiche Train- und Test-Split des Datensatzes verwendet werden (Reproduzierbarkeit). Dadurch wird sichergestellt, dass der Vergleich der Performanz konsistent ist und wir Äpfel mit Äpfeln vergleichen. Dies kann erreicht werden, indem der __random seed__ des Zufallszahlengenerators vor der Aufteilung der Daten auf die gleiche Weise festgelegt wird, oder indem dieselbe Aufteilung des Datensatzes auf alle Algorithmen angewandt wird.  "],"metadata":{}},{"cell_type":"markdown","source":["## Übung:\n","Nachdem Sie erfolgreich Ihre erste train/split Funktion geschrieben haben, dürfen Sie nun endlich die train/split-Funktion verwenden, die von der Scikit-Learn-Bibliothek bereitgestellt wird. Scikit-Learn sklearn ist eine häufig verwendete Bibliothek, die Ihre Produktivität booooooostet. \n","Es handelt sich hierbei um eine freie Software-Bibliothek für maschinelles Lernen in der Programmiersprache Python. Sie bietet verschiedene Klassifizierungs-, Regressions- und Clustering-Algorithmen, einschließlich Support-Vektor-Maschinen, Random Forests, Gradient Boosting, k-means und DBSCAN, und ist so konzipiert, dass sie mit den numerischen und wissenschaftlichen Python-Bibliotheken NumPy und SciPy zusammenarbeitet.\n","\n","Eine Auswahl von Funktionen finden Sie in dem [Scikit-Learn Cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Scikit_Learn_Cheat_Sheet_Python.pdf) (entnommen von https://www.datacamp.com/community/blog/scikit-learn-cheat-sheet). Beantworten Sie die folgende Frage, nachdem Sie das Cheatsheet durchgelesen haben: "],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.1.5:</b> Welche Funktion würden Sie zum Aufteilen des Datensatzes wählen? Welche Bibliothek würden Sie importieren?\n","</div>\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.1.6:</b> Welche Eingangsparameter hat die Funktion und was ist ihr Rückgabewert?\n","</div>\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n"],"metadata":{}},{"cell_type":"markdown","source":["Nun ist es an der Zeit, die Funktion zu verwenden. Zuerst werden wir die Funktion auf einen künstlichen Datensatz anwenden (nur die Zahlen von 1 bis 10).\n","Die Größe des Testsatzes soll 20 % betragen."],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Aufgabe 2.1.7:</b> Schreiben und testen Sie Ihre Lösung im folgenden Codeblock.\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["# Example of Splitting a Contrived Dataset into Train and Test\n","from random import seed\n","from random import randrange\n","\n","# test train/test split\n","dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(train)\n","print(test)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Übung: Pima-Indianer Diabetes-Datensatz\n","Der Datensatz ist im KI-Campus verfügbar. Das ursprüngliche Paper, das diesen Datensatz verwendet, finden Sie hier: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2245318/\n","In dieser Arbeit aus dem Jahr 1984 wurde ein Neuronales Netzwerkmodell für das Auftreten von Diabetes mellitus in einer Hochrisikopopulation von Pima-Indianern erstellt, mit einer Sensitivität und Spezifität von 76 %.\n","\n","__Datensatzinformationen:__\n","\n","Bei der Auswahl dieser Fälle aus einer größeren Datenbank wurden mehrere Einschränkungen gemacht. Insbesondere sind alle Patienten hier weiblich, mindestens 21 Jahre alt und stammen von Pima-Indianern ab.\n","\n","Informationen zu den Features:\n","\n","1. Anzahl der Schwangerschaften\n","2. Plasmaglukosekonzentration a 2 Stunden in einem oralen Glukosetoleranztest\n","3. Diastolischer Blutdruck (mm Hg)\n","4. Trizeps-Hautfaltendicke (mm)\n","5. 2-Stunden-Serum-Insulin (mu U/ml)\n","6. Body-Mass-Index (Gewicht in kg/(Größe in m)^2)\n","7. Diabetes-Stammbaumfunktion\n","8. Alter (Jahre)\n","9. Klassenvariable (0 oder 1)\n","\n","Nun, da Sie die Features des Datensatzes kennen, können wir mit der Codierung beginnen. \n","\n","<div class=\"alert block alert-warning\">\n","<b>Lösen Sie die Teilaufgaben 1-3 in den entsprechenden nachfolgenden Codeblöcken</b> \n","<ul>\n","  <li>Importieren Sie die CSV-Datei mit dem Datensatz der Pima-Indianer (verwenden Sie Abkürzungen für die Attribute)</li>\n","  <li>Wie viele Indianer haben keinen Diabetes (Klasse = 0) oder haben Diabetes (Klasse = 1)? Wie ist der Anteil/das Verhältnis dieser beiden Größen?</li>\n","  <li>Führen Sie einen Datensatzsplit mit der Methode train_test_split von sklearn mit einer Testgröße von 0,25<br> (bzw. einer train-Größe von 0,75) und einem random_state = 0 durch?</li>\n","</ul>\n","</div>\n"],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["# loading Libraries\n","from pandas import read_csv\n","import pandas as pd\n","import numpy as np\n","\n","#SUBTASK 1: Load the pima-indians-diabetes dataset\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["#SUBTASK 2:\n","\n","#How many Indians have diabetes (class =1) or have no diabetes (class = 0)? \n","#What is the proportion of these two quantities?\n","#Hint: the easiest way is to use the groupby method in combination of the size method\n","#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(\"Number of Indians without diabetes: \")\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(\"Number of Indians with diabetes: \")\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(\"Ratio of Indians with diabetes over those without diabetes: \")\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["#SUBTASK 3: \n","\n","#Divide the dataset into training and testing data using the train_test_split function\n","\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(\"Number of elements in the testset: \")\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(\"Number of elements in the trainingset: \")\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Bonusfrage:</b> Welche indische Frau (ID) hatte den dicksten Arm?\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Frage 2.1.8:</b> Was wäre der Nachteil, wenn die Verteilung der Klassen (in unserem Datensatz Klasse 0/1) im Trainingsdatensatz anders wäre als im Testdatensatz? Zum Beispiel, wenn die Klasse 1 80 % des Trainingsdatensatzes ausmacht, aber nur 20 % im Testdatensatz.\n","\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n","\n"],"metadata":{}},{"cell_type":"markdown","source":["## Kreuz-Validierung (engl. Cross-Validation)\n","\n","Kreuzvalidierungsverfahren lassen sich einteilen in:\n","- __erschöpfend:__ Daten werden in Trainings- und Validierungssätze aufgeteilt. Es werden alle Möglichkeiten zur Aufteilung der Daten erprobt.  Zu dieser Gruppe gehören:\n","    - Leave One Out Cross-Validation (ein Spezialfall der \"Leave-p-out cross-validation\")\n","\n","- __nicht-erschöpfend:__ Die Methode berechnet nicht alle möglichen Wege der Aufteilung der Daten.  Bekannte Beispiele sind: \n","    - k-fache Kreuzvalidierung\n","    - Wiederholte zufällige Test-Train-Splits\n","    - Holdout-Methode\n","    \n","### k-fache Kreuzvalidierung (engl. k-fold Cross-Validation)\n","Die __k-fold Cross-Validation__ (k-fold CV) - Methode ist eine Resampling-Methode, die eine genauere Schätzung der Algorithmus-Performanz liefert, also mit einer geringeren Varianz als eine einfache Training-Test-Satz-Aufteilung.  \n","\n","Hierbei wird der Datensatz zunächst in k Gruppen aufgeteilt. Jede Gruppe von Daten wird als Fold bezeichnet, daher der Name k-fold cross-validation.\n","\n","In der folgenden Abbildung sehen Sie, dass jede Zeile einen Fold und jede Spalte eine Trainings- und Testiteration darstellt. Zum Beispiel wird in der ersten Iteration (Modell 1) die Fold 1 die Testfalte sein und die anderen die Trainingsfalten.\n","![Imagen K-fold](images/K-fold_cross_validation_EN.jpg)\n","\n","Der Algorithmus wird dann k-mal trainiert und evaluiert. Die Performanz wird anschließend zusammengefasst, indem der Mittelwert der Performanz aller Evaluierungen gebildet wird. \n","\n","Der Algorithmus wird auf k - 1 Folds der Daten trainiert und dann auf der k-ten zurückgehaltenen Fold getestet. \n","Dies wird wiederholt, so dass jede der k Folds des Datensatzes eine Chance erhält, zurückgehalten und als Testsatz verwendet zu werden. Beachten Sie aber, dass dabei auch k getrennte Modelle trainiert werden, sodass ein Testsatz nie für das Training eines Modells verwendet wird.\n","\n","Daher sollte die Anzahl der Zeilen in Ihrem Trainingsdatensatz durch k teilbar sein, um sicherzustellen, dass jede der k Gruppen die gleiche Anzahl von Zeilen hat.  \n","\n","Sie sollten einen Wert für k wählen, der die Daten in Folds mit genügend Zeilen aufteilt, so dass jeder Fold immer noch groß genug ist, um den Originaldatensatzes gut zu repräsentieren. Es sollten jedoch immer genügend Folds vorhanden sein, damit die Anzahl der Wiederholungen der Train-Test-Auswertung des Algorithmus ausreicht, um eine angemessene Schätzung der Leistung der Algorithmen zu liefern.\n","\n","Für Datensätze von geringer Größe (Hunderte, Tausende oder Zehntausende von Zeilen) ist es eine gute Idee, k=3 für einen kleinen Datensatz oder k=10 für einen größeren Datensatz zu verwenden. Eine schnelle Möglichkeit um zu überprüfen, ob die Fold-Größen repräsentativ sind, ist die Berechnung von zusammenfassenden Statistiken wie der Mittelwert und die Standardabweichung. So könenn Sie herausfinden, wie sehr sich die Werte von den gleichen Statistiken für den gesamten Datensatz unterscheiden.\n","\n","Wir können die Größe der Folds berechnen, indem wir die Größe des Datensatzes durch die Anzahl der erforderlichen Faltungen teilen:  \n","\n","$ \\textrm{fold size} = \\frac{\\textrm{Number of rows}}{\\textrm{k}} = \\frac{\\textrm{Number of rows}}{\\textrm{Number of folds}} = \\frac{count(rows)}{count(folds)} $\n","\n","Wenn der Datensatz nicht sauber durch die Anzahl der Faltungen geteilt werden kann, kann es einige Restzeilen geben. Diese werden bei der Aufteilung nicht verwendet.\n","\n","Nach Durchführung der Kreuzvalidierung erhalten Sie k verschiedene Performanz-Werte, die Sie mit einem Mittelwert und einer Standardabweichung zusammenfassen können.  \n","\n","Das Ergebnis ist eine zuverlässigere Schätzung der Leistung des Algorithmus auf neuen Daten. Es ist genauer, weil der Algorithmus mehrfach auf verschiedenen Daten trainiert und bewertet wurde.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Tipp:</b> Wenn Sie nach dem Lesen dieses Abschnitts Probleme haben, die k-fold Cross-Validation zu verstehen. So empfiehlt sich, ein Youtube-Video über k-fold Cross-Validation anzuschauen. Die Visualisierung kann Ihnen dabei helfen, den Zusammenhang besser zu verstehen.\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Freiwillige Aufgabe:</b> Ihre Aufgabe ist es, die Funktion K-fold Cross-Validation von Grund auf zu implementieren. Der Rest des Codes wird als Anleitung gegeben.\n","<ul>\n","<li> Die Funktion erhält den Originaldatensatz und die Anzahl der Folds, die wir erhalten wollen, und gibt eine Liste zurück, die die k Folds enthält (in diesem Fall soll sie 4 Faltungen zurückgeben).\n","<li> Wir wollen, dass die Aufteilung zufällig ist, daher müssen Sie wahrscheinlich aus dem Modul \"random.py\" (das Teil der Python-Standardbibliothek ist) die Funktionen seed und randrange importieren. Die seed-Funktion wird dafür sorgen, dass das Ergebnis von randrange bei jeder Ausführung des Codes gleich ist.\n","\n","</ul>\n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["# Example of Creating a Cross Validation Split\n","from random import seed\n","from random import randrange\n","\n","# Split a dataset into k folds\n","def cross_validation_split(dataset: pd.DataFrame, folds:int=3):\n","\n","    dataset_split = list() # Creates an empty list in \"dataset_split\"\n","    dataset_copy = list(dataset) # Creates an empty list and copies the dataset in it\n","    fold_size = int(len(dataset) / folds) # Determine the number of elements for each fold\n","    print(\"Quantity of elements that each fold will have: \", fold_size)\n","    # HINT: use a for loop to iterate through the number of folds and use a while loop to populate the individual folds\n","    # HINT: You might want to use randrange to get a random index of the available dataset\n","    \n","    #STUDENT CODE HERE\n","\n","    #STUDENT CODE until HERE\n","    \n","    return dataset_split\n","\n","# test cross validation split\n","seed(1)\n","dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n","folds = cross_validation_split(dataset, 4)\n","print(folds)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["So weit, so gut! Jetzt haben wir verstanden, wie wir die Folds mit unserer eigenen Funktion erzeugen können. Aber was wäre, wenn es eine solche Funktion bereits da draußen in der Wildnis gäbe? Tatsächlich ist das der Fall! Normalerweise codet der Machine-Learning-Ingenieur seine Splits nicht selber, sondern verwendet solche bereits vorhandenen Funktionen. Also probieren wir es aus und verwenden hierbei wieder einmal die Pima-Indians-Diabetes-Datenbank. \n"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Freiwillige Aufgabe:</b> Berechnen Sie den Mittelwert und die Varianz der Genauigkeit des Modells, um herauszufinden, ob das k gut gewählt wurde, oder ob wir es anpassen sollten. In dieser Aufgabe werden wir ein lineares Regressionsmodell verwenden.\n","<ul>\n","<li>Hinweis 1: Die Funktion <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\">cross_val_score</a> kann uns dabei helfen. \n","<br>\n","<li>Hinweis 2: Verwenden Sie diese Funktion für die Regression: LogisticRegression (solver = 'liblinear')\n","\n","</ul>\n","</div>"],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Freiwillige Frage:</b> Was passiert mit der Genauigkeit und der Varianz, wenn k zunimmt? Wie können Sie die Veränderung der Varianz erklären?\n","</div>\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"code","execution_count":10,"source":["# Evaluate using Cross Validation\n","from pandas import read_csv\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","\n","filename = 'data/pima-indians-diabetes.data.csv'\n","names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","dataframe = read_csv(filename, names=names)\n","array = dataframe.values\n","X = array[:,0:8]\n","Y = array[:,8]\n","\n","#There might be a function which can do \"KFold\" with respect to class distribution. What could be the name?\n","#Hint: Check the Note below\n","#Hint: you should be able to do this in less then 5 lines\n","#Hint: you don't need to explicitly fit your model, because \"cross_val_score\" does this automatically\n","#STUDENT CODE HERE\n","\n","#STUDENT CODE until HERE\n","\n","print(results)\n","\n","print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Geschichtete Zufallsstichprobe (engl. Stratification Sampling)\n","\n","Geschichtete Zufallsstichprobe versucht, einen Datensatz so zu unterteilen, dass jede Aufteilung in Bezug auf etwas ähnlich ist.\n","\n","Im Bereich der Klassifizierung wird es oft verwendet um sicherzustellen, dass Trainings- und Testdatensätze ungefähr den gleichen Prozentsatz an Proben jeder Zielklasse aufweisen wie der vollständige Datensatz.\n","\n","<div class=\"alert alert-block alert-success\">\n","<b>Optionale Aufgabe:</b> Fügen Sie der Methode train_test_split den Parameter stratify hinzu. \n","</div>"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["#Save features and targets in a separate data structure\n","features = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n","target = ['class']\n","features, targets = diabetes_dataset[features], diabetes_dataset[target]\n","\n","#Use the train_test_split function for splitting data.\n","#Task: Add the correct stratify parameter to the function call\n","\n","train_features, test_features, train_targets, test_targets = train_test_split(\n","        features, targets,\n","        train_size=0.75,\n","        test_size=0.25,\n","        random_state=41, # important for later, do not change yet\n","        #STUDENT CODE HERE\n","\n","        #STUDENT CODE until HERE\n","    )\n","\n","print(\"Proportion of 'targets' in test and train dataset\")\n","print(\"Training:\", np.bincount(train_targets.values.flatten()) / float(len(train_targets)))\n","print(\"Test:\", np.bincount(test_targets.values.flatten())/ float(len(test_targets)))"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\">\n","<b>Freiwillige Aufgabe:</b> Was haben wir durch das stratifizierte Sampling erreicht? Schauen Sie sich die Ausgabe des vorherigen Codeblocks an und beschreiben Sie diese mit eigenen Worten. \n","\n","(Besprechen Sie dies mit Ihrem Partner, bevor Sie anfangen, etwas zu googeln wie: \"stratification machine learning\")\n","</div>\n","\n","\n","<div class=\"alert block alert-success\">\n","<b>Ihre Antwort:</b></div>\n"],"metadata":{}},{"cell_type":"markdown","source":["## Auswählen einer Resampling-Methode\n","\n","- Allgemeinen ist die k-fold Cross-Validation der Goldstandard für die Bewertung der Performanz eines Algorithmus des maschinellen Lernens, wobei k auf 3, 5 oder 10 gesetzt wird.  \n","Wenn sie gut konfiguriert ist, liefert die k-fold Cross-Validation eine robuste Schätzung der Leistung im Vergleich zu anderen Methoden, wie z. B. der Aufteilung in Train und Test. Der Nachteil der Kreuzvalidierung ist, dass sie zeitaufwändig sein kann, da k verschiedene Modelle trainiert und ausgewertet werden müssen. Dies ist ein Problem, wenn Sie einen sehr großen Datensatz haben oder wenn Sie ein Modell evaluieren, dessen Training sehr lange dauert.  \n","\n","\n","- Die Trainings- und Test-Split Resampling-Methode wird am häufigsten verwendet. Der Grund dafür ist, dass sie einfach zu verstehen und zu implementieren ist. Sie fördert die Geschwindigkeit, wenn ein langsamer Algorithmus verwendet wird, da nur ein einziges Modell konstruiert und ausgewertet wird. \n","Diese Methode kann eine verrauschte oder unzuverlässige Schätzung der Leistung liefern, aber das wird weniger zum Problem, wenn Sie einen sehr großen Datensatz verwenden. In diesem Fall erzeugt dieser Ansatz geringere Verzerrung.\n","Große Datensätze haben Hunderttausenden oder Millionen von Einträgen, und sind damit so groß, dass die Training- und Test-Splits nahezu die gleichen statistischen Eigenschaften aufweisen.\n","In solchen Fällen ist die Verwendung der k-fold Cross-Validation zur Evaluierung des Algorithmus möglicherweise nicht notwendig und eine Aufteilung in Train und Test kann genauso zuverlässig sein.\n","\n","\n","- Verfahren wie die Leave-One-Out-Cross-Validation und wiederholte zufällige Splits können nützliche Zwischenstufen sein, um einen Mittelweg zwischen der Varianz der geschätzten Performanz, der Trainingsgeschwindigkeit des Modells und der Größe des Datensatzes zu finden.\n","\n","Es ist sinnvoll, verschiedene Möglichkeiten auszuprobieren, um eine Technik für ihr Problem zu finden, die schnell ist, aber gleichzeitig auch eine vernünftige Schätzungen der Performanz liefert, auf Basis derer sie dann eine Entscheidung treffen können. Im Zweifelsfall sollten Sie die 10-fold Cross-Validation verwenden.\n"],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python-amalea"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":4}
